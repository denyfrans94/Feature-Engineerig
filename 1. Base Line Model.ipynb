{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this micro-course, you will learn a practical approach to feature engineering. You'll be able to apply what you learn to Kaggle competitions as well as building machine learning applications. Through hands-on exercises you will:\n",
    "\n",
    "- Develop a baseline model for comparing performance on models with more features\n",
    "- Encode categorical features so the model can make better use of the information\n",
    "- Generate new features to provide more information for the model\n",
    "- Select features to reduce overfitting and increase prediction speed\n",
    "\n",
    "In the exercise, you will apply feature engineering techniques to data from the TalkingData AdTracking competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the competition is to predict if a user will download an app after clicking through an ad. For this course you will use a small sample of the data, dropping 99% of negative records (where the app wasn't downloaded) to make the target more balanced.\n",
    "\n",
    "Kickstarter projects\n",
    "To help you apply the techniques, you'll first see them applied using data from Kickstarter projects. The first few rows of the Kickstarter projects data looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kickstarter projects\n",
    "To help you apply the techniques, you'll first see them applied using data from Kickstarter projects. The first few rows of the Kickstarter projects data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>canceled</td>\n",
       "      <td>14</td>\n",
       "      <td>US</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>19500.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "\n",
       "         category main_category currency   deadline     goal  \\\n",
       "0          Poetry    Publishing      GBP 2015-10-09   1000.0   \n",
       "1  Narrative Film  Film & Video      USD 2017-11-01  30000.0   \n",
       "2  Narrative Film  Film & Video      USD 2013-02-26  45000.0   \n",
       "3           Music         Music      USD 2012-04-16   5000.0   \n",
       "4    Film & Video  Film & Video      USD 2015-08-29  19500.0   \n",
       "\n",
       "             launched  pledged     state  backers country  usd pledged  \\\n",
       "0 2015-08-11 12:12:28      0.0    failed        0      GB          0.0   \n",
       "1 2017-09-02 04:43:57   2421.0    failed       15      US        100.0   \n",
       "2 2013-01-12 00:20:50    220.0    failed        3      US        220.0   \n",
       "3 2012-03-17 03:24:11      1.0    failed        1      US          1.0   \n",
       "4 2015-07-04 08:35:03   1283.0  canceled       14      US       1283.0   \n",
       "\n",
       "   usd_pledged_real  usd_goal_real  \n",
       "0               0.0        1533.95  \n",
       "1            2421.0       30000.00  \n",
       "2             220.0       45000.00  \n",
       "3               1.0        5000.00  \n",
       "4            1283.0       19500.00  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ks = pd.read_csv('Dataset/kickstarter-projects/ks-projects-201801.csv', parse_dates=['deadline', 'launched'])\n",
    "ks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do here is predict if a Kickstarter project will succeed. We get the outcome from the state column. To predict the outcome we can use features such as category, currency, funding goal, country, and when it was launched.\n",
    "\n",
    "### Preparing target column\n",
    "First I'll look at project states and convert the column into something we can use as targets in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['failed', 'canceled', 'successful', 'live', 'undefined',\n",
       "       'suspended'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(ks.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have six states, how many records of each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "canceled       38779\n",
       "failed        197719\n",
       "live            2799\n",
       "successful    133956\n",
       "suspended       1846\n",
       "undefined       3562\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks.groupby('state')['ID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning isn't the current focus, so we'll simplify this example by:\n",
    "\n",
    "- Dropping projects that are \"live\"\n",
    "- Counting \"successful\" states as outcome = 1\n",
    "- Combining every other state as outcome = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop live projects\n",
    "ks = ks.query('state != \"live\"' )\n",
    "\n",
    "# Add outcome column, \"successful\" == 1, others are 0\n",
    "ks = ks.assign(outcome=(ks['state'] == 'successful').astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting timestamps\n",
    "I convert the launched feature into categorical features we can use in a model. Since I loaded in the columns as timestamp data, I access date and time values through the .dt attribute on the timestamp column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>outcome</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>canceled</td>\n",
       "      <td>14</td>\n",
       "      <td>US</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>19500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000014025</td>\n",
       "      <td>Monarch Espresso Bar</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2016-02-26 13:38:27</td>\n",
       "      <td>52375.0</td>\n",
       "      <td>successful</td>\n",
       "      <td>224</td>\n",
       "      <td>US</td>\n",
       "      <td>52375.0</td>\n",
       "      <td>52375.0</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000023410</td>\n",
       "      <td>Support Solar Roasted Coffee &amp; Green Energy!  ...</td>\n",
       "      <td>Food</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>2014-12-21</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2014-12-01 18:30:44</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>successful</td>\n",
       "      <td>16</td>\n",
       "      <td>US</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "4  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "5  1000014025                               Monarch Espresso Bar   \n",
       "6  1000023410  Support Solar Roasted Coffee & Green Energy!  ...   \n",
       "\n",
       "         category main_category currency   deadline     goal  \\\n",
       "0          Poetry    Publishing      GBP 2015-10-09   1000.0   \n",
       "1  Narrative Film  Film & Video      USD 2017-11-01  30000.0   \n",
       "2  Narrative Film  Film & Video      USD 2013-02-26  45000.0   \n",
       "3           Music         Music      USD 2012-04-16   5000.0   \n",
       "4    Film & Video  Film & Video      USD 2015-08-29  19500.0   \n",
       "5     Restaurants          Food      USD 2016-04-01  50000.0   \n",
       "6            Food          Food      USD 2014-12-21   1000.0   \n",
       "\n",
       "             launched  pledged       state  backers country  usd pledged  \\\n",
       "0 2015-08-11 12:12:28      0.0      failed        0      GB          0.0   \n",
       "1 2017-09-02 04:43:57   2421.0      failed       15      US        100.0   \n",
       "2 2013-01-12 00:20:50    220.0      failed        3      US        220.0   \n",
       "3 2012-03-17 03:24:11      1.0      failed        1      US          1.0   \n",
       "4 2015-07-04 08:35:03   1283.0    canceled       14      US       1283.0   \n",
       "5 2016-02-26 13:38:27  52375.0  successful      224      US      52375.0   \n",
       "6 2014-12-01 18:30:44   1205.0  successful       16      US       1205.0   \n",
       "\n",
       "   usd_pledged_real  usd_goal_real  outcome  hour  day  month  year  \n",
       "0               0.0        1533.95        0    12   11      8  2015  \n",
       "1            2421.0       30000.00        0     4    2      9  2017  \n",
       "2             220.0       45000.00        0     0   12      1  2013  \n",
       "3               1.0        5000.00        0     3   17      3  2012  \n",
       "4            1283.0       19500.00        0     8    4      7  2015  \n",
       "5           52375.0       50000.00        1    13   26      2  2016  \n",
       "6            1205.0        1000.00        1    18    1     12  2014  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks = ks.assign(hour=ks.launched.dt.hour,\n",
    "               day=ks.launched.dt.day,\n",
    "               month=ks.launched.dt.month,\n",
    "               year=ks.launched.dt.year)\n",
    "\n",
    "ks.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping categorical variables\n",
    "Now for the categorical variables -- category, currency, and country -- I'll need to convert them into integers so our model can use the data. For this I'll use scikit-learn's LabelEncoder. This assigns an integer to each value of the categorical feature and replaces those values with the integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>currency</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category  currency  country\n",
       "0       108         5        9\n",
       "1        93        13       22\n",
       "2        93        13       22\n",
       "3        90        13       22\n",
       "4        55        13       22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_features = ['category', 'currency', 'country']\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Apply the label encoder to each column\n",
    "encoded = ks[cat_features].apply(encoder.fit_transform)\n",
    "encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll collect all the features we'll use in a new dataframe and use that to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>outcome</th>\n",
       "      <th>category</th>\n",
       "      <th>currency</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19500.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      goal  hour  day  month  year  outcome  category  currency  country\n",
       "0   1000.0    12   11      8  2015        0       108         5        9\n",
       "1  30000.0     4    2      9  2017        0        93        13       22\n",
       "2  45000.0     0   12      1  2013        0        93        13       22\n",
       "3   5000.0     3   17      3  2012        0        90        13       22\n",
       "4  19500.0     8    4      7  2015        0        55        13       22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since ks and encoded have the same index and I can easily join them\n",
    "data = ks[['goal', 'hour', 'day', 'month', 'year', 'outcome']].join(encoded)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training, validation, and test splits\n",
    "We need to create data sets for training, validation, and testing. We'll use a fairly simple approach and split the data using slices. We'll use 10% of the data as a validation set, 10% for testing, and the other 80% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fraction = 0.1\n",
    "valid_size = int(len(data) * valid_fraction)\n",
    "\n",
    "train = data[:-2 * valid_size]\n",
    "valid = data[-2 * valid_size:-valid_size]\n",
    "test = data[-valid_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general you want to be careful that each data set has the same proportion of target classes. I'll print out the fraction of successful outcomes for each of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome Fraction = 0.3570\n",
      "Outcome Fraction = 0.3539\n",
      "Outcome Fraction = 0.3542\n"
     ]
    }
   ],
   "source": [
    "for  each in [train, valid, test]:\n",
    "    print(f'Outcome Fraction = {each.outcome.mean():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, each set is around 35% true outcomes likely because the data was well randomized beforehand. A good way to do this automatically is with sklearn.model_selection.StratifiedShuffleSplit but I don't need to use it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a LightGBM model\n",
    "For this course we'll be using a LightGBM model. This is a tree-based model that typically provides the best performance, even compared to XGBoost. It's also relatively fast to train. We won't do hyperparameter optimization because that isn't the goal of this course. So, our models won't be the absolute best performance you can get. But you'll still see model performance improve as we do feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\deny frans\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\deny frans\\anaconda3\\lib\\site-packages (from lightgbm) (0.22.2.post1)\n",
      "Requirement already satisfied: numpy in c:\\users\\deny frans\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\deny frans\\anaconda3\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\deny frans\\anaconda3\\lib\\site-packages (from scikit-learn->lightgbm) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "feature_cols = train.columns.drop('outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = lgb.Dataset(train[feature_cols], label=train['outcome'])\n",
    "dvalid = lgb.Dataset(valid[feature_cols], label=valid['outcome'])\n",
    "\n",
    "param = {'num_leaves':64, 'objective':'binary'}\n",
    "param['metric'] = 'auc'\n",
    "num_round = 1000\n",
    "bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=10, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions & evaluating the model\n",
    "Finally, let's make predictions on the test set with the model and see how well it performs. An important thing to remember is that you can overfit to the validation data. This is why we need a test set that the model never sees until the final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Predicted : [0.46018401 0.49095702 0.42567723 ... 0.35852514 0.22526392 0.53888705]\n",
      "Test AUC score : 0.747615303004287\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "ypred = bst.predict(test[feature_cols])\n",
    "score = metrics.roc_auc_score(test['outcome'], ypred)\n",
    "\n",
    "print(f'Test Predicted : {ypred}')\n",
    "print(f'Test AUC score : {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "Now you'll build your own baseline model which you can improve with feature engineering techniques as you go through the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Baseline Model c21333\n",
    "## Introduction\n",
    "\n",
    "In this exercise, you will develop a baseline model for predicting if a customer will buy an app after clicking on an ad. With this baseline model, you'll be able to see how your feature engineering and selection efforts improve the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89489</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 15:13:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204158</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>2017-11-06 15:41:07</td>\n",
       "      <td>2017-11-07 08:17:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3437</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 15:42:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167543</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 15:56:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147509</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 15:57:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel          click_time      attributed_time  \\\n",
       "0   89489    3       1  13      379 2017-11-06 15:13:23                  NaN   \n",
       "1  204158   35       1  13       21 2017-11-06 15:41:07  2017-11-07 08:17:19   \n",
       "2    3437    6       1  13      459 2017-11-06 15:42:32                  NaN   \n",
       "3  167543    3       1  13      379 2017-11-06 15:56:17                  NaN   \n",
       "4  147509    3       1  13      379 2017-11-06 15:57:01                  NaN   \n",
       "\n",
       "   is_attributed  \n",
       "0              0  \n",
       "1              1  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_data = pd.read_csv('train_sample.csv', parse_dates=['click_time'])\n",
    "\n",
    "click_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "The first thing you need to do is construct a baseline model. All new features, processing, encodings, and feature selection should improve upon this baseline model. First you need to do a bit of feature engineering before training the model itself.\n",
    "\n",
    "#### 1) Features from timestamps\n",
    "From the timestamps, create features for the day, hour, minute and second. Store these as new integer columns `day`, `hour`, `minute`, and `second` in a new DataFrame `clicks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns for timestamp features day, hour, minute, and second\n",
    "clicks = click_data.copy()\n",
    "clicks['day'] = clicks['click_time'].dt.day.astype('uint8')\n",
    "# Fill in the rest\n",
    "clicks['hour'] = clicks['click_time'].dt.hour.astype('uint8')\n",
    "clicks['minute'] = clicks['click_time'].dt.minute.astype('uint8')\n",
    "clicks['second'] = clicks['click_time'].dt.second.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Label Encoding\n",
    "For each of the categorical features `['ip', 'app', 'device', 'os', 'channel']`, use scikit-learn's `LabelEncoder` to create new features in the `clicks` DataFrame. The new column names should be the original column name with `'_labels'` appended, like `ip_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "\n",
    "# Create new columns in clicks using preprocessing.LabelEncoder()\n",
    "label_encoder = LabelEncoder()\n",
    "for feature in cat_features:\n",
    "    encoded = label_encoder.fit_transform(clicks[feature])\n",
    "    clicks[feature + '_labels'] = encoded\n",
    "    \n",
    "#     encoded = clicks[cat_features].apply(encoder.fit_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>ip_labels</th>\n",
       "      <th>app_labels</th>\n",
       "      <th>device_labels</th>\n",
       "      <th>os_labels</th>\n",
       "      <th>channel_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89489</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 15:13:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>27226</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204158</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>2017-11-06 15:41:07</td>\n",
       "      <td>2017-11-07 08:17:19</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>110007</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3437</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>459</td>\n",
       "      <td>2017-11-06 15:42:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>1047</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167543</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 15:56:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>76270</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147509</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 15:57:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>57862</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel          click_time      attributed_time  \\\n",
       "0   89489    3       1  13      379 2017-11-06 15:13:23                  NaN   \n",
       "1  204158   35       1  13       21 2017-11-06 15:41:07  2017-11-07 08:17:19   \n",
       "2    3437    6       1  13      459 2017-11-06 15:42:32                  NaN   \n",
       "3  167543    3       1  13      379 2017-11-06 15:56:17                  NaN   \n",
       "4  147509    3       1  13      379 2017-11-06 15:57:01                  NaN   \n",
       "\n",
       "   is_attributed  day  hour  minute  second  ip_labels  app_labels  \\\n",
       "0              0    6    15      13      23      27226           3   \n",
       "1              1    6    15      41       7     110007          35   \n",
       "2              0    6    15      42      32       1047           6   \n",
       "3              0    6    15      56      17      76270           3   \n",
       "4              0    6    15      57       1      57862           3   \n",
       "\n",
       "   device_labels  os_labels  channel_labels  \n",
       "0              1         13             120  \n",
       "1              1         13              10  \n",
       "2              1         13             157  \n",
       "3              1         13             120  \n",
       "4              1         13             120  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) One-hot Encoding\n",
    "\n",
    "Now you have label encoded features, does it make sense to use one-hot encoding for the categorical variables ip, app, device, os, or channel?\n",
    "\n",
    "Run the following line after you've decided your answer.\n",
    "\n",
    "Solution: The ip column has 58,000 values, which means it will create an extremely sparse matrix with 58,000 columns. This many columns will make your model run very slow, so in general you want to avoid one-hot encoding features with many levels. LightGBM models work with label encoded features, so you don't actually need to one-hot encode the categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, validation, and test sets\n",
    "With our baseline features ready, we need to split our data into training and validation sets. We should also hold out a test set to measure the final accuracy of the model.\n",
    "\n",
    "#### 4) Train/test splits with time series data\n",
    "This is time series data. Are they any special considerations when creating train/test splits for time series? If so, what and why?\n",
    "\n",
    "Uncomment the following line after you've decided your answer.\n",
    "\n",
    "Solution: Since our model is meant to predict events in the future, we must also validate the model on events in the future. If the data is mixed up between the training and test sets, then future data will leak in to the model and our validation results will overestimate the performance on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train/validation/test splits\n",
    "\n",
    "Here we'll create training, validation, and test splits. First, `clicks` DataFrame is sorted in order of increasing time. The first 80% of the rows are the train set, the next 10% are the validation set, and the last 10% are the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['day', 'hour', 'minute', 'second', \n",
    "                'ip_labels', 'app_labels', 'device_labels',\n",
    "                'os_labels', 'channel_labels']\n",
    "\n",
    "valid_fraction = 0.1\n",
    "click_srt = clicks.sort_values('click_time')\n",
    "valid_rows = int(len(click_srt) * valid_fraction)\n",
    "train = click_srt[:-valid_rows * 2]\n",
    "# valid size == test size, last two sections of the data\n",
    "valid = click_srt[-valid_rows * 2:-valid_rows]\n",
    "test = click_srt[-valid_rows:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with LightGBM\n",
    "\n",
    "Now we can create LightGBM dataset objects for each of the smaller datasets and train the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.948979\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's auc: 0.949235\n",
      "[3]\tvalid_0's auc: 0.950126\n",
      "[4]\tvalid_0's auc: 0.950072\n",
      "[5]\tvalid_0's auc: 0.950536\n",
      "[6]\tvalid_0's auc: 0.950943\n",
      "[7]\tvalid_0's auc: 0.951453\n",
      "[8]\tvalid_0's auc: 0.951518\n",
      "[9]\tvalid_0's auc: 0.952385\n",
      "[10]\tvalid_0's auc: 0.952434\n",
      "[11]\tvalid_0's auc: 0.952465\n",
      "[12]\tvalid_0's auc: 0.952638\n",
      "[13]\tvalid_0's auc: 0.95266\n",
      "[14]\tvalid_0's auc: 0.952766\n",
      "[15]\tvalid_0's auc: 0.953203\n",
      "[16]\tvalid_0's auc: 0.953503\n",
      "[17]\tvalid_0's auc: 0.953793\n",
      "[18]\tvalid_0's auc: 0.953966\n",
      "[19]\tvalid_0's auc: 0.954184\n",
      "[20]\tvalid_0's auc: 0.9543\n",
      "[21]\tvalid_0's auc: 0.954305\n",
      "[22]\tvalid_0's auc: 0.954536\n",
      "[23]\tvalid_0's auc: 0.954748\n",
      "[24]\tvalid_0's auc: 0.955142\n",
      "[25]\tvalid_0's auc: 0.955493\n",
      "[26]\tvalid_0's auc: 0.955611\n",
      "[27]\tvalid_0's auc: 0.955708\n",
      "[28]\tvalid_0's auc: 0.955795\n",
      "[29]\tvalid_0's auc: 0.956172\n",
      "[30]\tvalid_0's auc: 0.95623\n",
      "[31]\tvalid_0's auc: 0.956477\n",
      "[32]\tvalid_0's auc: 0.956606\n",
      "[33]\tvalid_0's auc: 0.956864\n",
      "[34]\tvalid_0's auc: 0.957204\n",
      "[35]\tvalid_0's auc: 0.957327\n",
      "[36]\tvalid_0's auc: 0.957408\n",
      "[37]\tvalid_0's auc: 0.957524\n",
      "[38]\tvalid_0's auc: 0.957659\n",
      "[39]\tvalid_0's auc: 0.957846\n",
      "[40]\tvalid_0's auc: 0.958042\n",
      "[41]\tvalid_0's auc: 0.958146\n",
      "[42]\tvalid_0's auc: 0.958181\n",
      "[43]\tvalid_0's auc: 0.958285\n",
      "[44]\tvalid_0's auc: 0.958433\n",
      "[45]\tvalid_0's auc: 0.95854\n",
      "[46]\tvalid_0's auc: 0.958625\n",
      "[47]\tvalid_0's auc: 0.958756\n",
      "[48]\tvalid_0's auc: 0.958863\n",
      "[49]\tvalid_0's auc: 0.958938\n",
      "[50]\tvalid_0's auc: 0.959046\n",
      "[51]\tvalid_0's auc: 0.95908\n",
      "[52]\tvalid_0's auc: 0.959147\n",
      "[53]\tvalid_0's auc: 0.9592\n",
      "[54]\tvalid_0's auc: 0.959259\n",
      "[55]\tvalid_0's auc: 0.959311\n",
      "[56]\tvalid_0's auc: 0.959324\n",
      "[57]\tvalid_0's auc: 0.959348\n",
      "[58]\tvalid_0's auc: 0.959435\n",
      "[59]\tvalid_0's auc: 0.959463\n",
      "[60]\tvalid_0's auc: 0.95949\n",
      "[61]\tvalid_0's auc: 0.959562\n",
      "[62]\tvalid_0's auc: 0.959721\n",
      "[63]\tvalid_0's auc: 0.959729\n",
      "[64]\tvalid_0's auc: 0.959773\n",
      "[65]\tvalid_0's auc: 0.959809\n",
      "[66]\tvalid_0's auc: 0.959868\n",
      "[67]\tvalid_0's auc: 0.959921\n",
      "[68]\tvalid_0's auc: 0.959994\n",
      "[69]\tvalid_0's auc: 0.960065\n",
      "[70]\tvalid_0's auc: 0.96011\n",
      "[71]\tvalid_0's auc: 0.960133\n",
      "[72]\tvalid_0's auc: 0.960275\n",
      "[73]\tvalid_0's auc: 0.960299\n",
      "[74]\tvalid_0's auc: 0.960336\n",
      "[75]\tvalid_0's auc: 0.960365\n",
      "[76]\tvalid_0's auc: 0.960411\n",
      "[77]\tvalid_0's auc: 0.960488\n",
      "[78]\tvalid_0's auc: 0.960523\n",
      "[79]\tvalid_0's auc: 0.960563\n",
      "[80]\tvalid_0's auc: 0.960624\n",
      "[81]\tvalid_0's auc: 0.960665\n",
      "[82]\tvalid_0's auc: 0.960724\n",
      "[83]\tvalid_0's auc: 0.960724\n",
      "[84]\tvalid_0's auc: 0.960751\n",
      "[85]\tvalid_0's auc: 0.960799\n",
      "[86]\tvalid_0's auc: 0.960853\n",
      "[87]\tvalid_0's auc: 0.960876\n",
      "[88]\tvalid_0's auc: 0.960934\n",
      "[89]\tvalid_0's auc: 0.961012\n",
      "[90]\tvalid_0's auc: 0.961012\n",
      "[91]\tvalid_0's auc: 0.961065\n",
      "[92]\tvalid_0's auc: 0.961095\n",
      "[93]\tvalid_0's auc: 0.961131\n",
      "[94]\tvalid_0's auc: 0.961136\n",
      "[95]\tvalid_0's auc: 0.961155\n",
      "[96]\tvalid_0's auc: 0.961191\n",
      "[97]\tvalid_0's auc: 0.961189\n",
      "[98]\tvalid_0's auc: 0.961189\n",
      "[99]\tvalid_0's auc: 0.961224\n",
      "[100]\tvalid_0's auc: 0.961228\n",
      "[101]\tvalid_0's auc: 0.96125\n",
      "[102]\tvalid_0's auc: 0.961259\n",
      "[103]\tvalid_0's auc: 0.961289\n",
      "[104]\tvalid_0's auc: 0.961309\n",
      "[105]\tvalid_0's auc: 0.961309\n",
      "[106]\tvalid_0's auc: 0.96134\n",
      "[107]\tvalid_0's auc: 0.961373\n",
      "[108]\tvalid_0's auc: 0.961382\n",
      "[109]\tvalid_0's auc: 0.961391\n",
      "[110]\tvalid_0's auc: 0.961402\n",
      "[111]\tvalid_0's auc: 0.961449\n",
      "[112]\tvalid_0's auc: 0.96145\n",
      "[113]\tvalid_0's auc: 0.961482\n",
      "[114]\tvalid_0's auc: 0.961481\n",
      "[115]\tvalid_0's auc: 0.961492\n",
      "[116]\tvalid_0's auc: 0.961513\n",
      "[117]\tvalid_0's auc: 0.961531\n",
      "[118]\tvalid_0's auc: 0.961539\n",
      "[119]\tvalid_0's auc: 0.961563\n",
      "[120]\tvalid_0's auc: 0.961563\n",
      "[121]\tvalid_0's auc: 0.961568\n",
      "[122]\tvalid_0's auc: 0.961588\n",
      "[123]\tvalid_0's auc: 0.961599\n",
      "[124]\tvalid_0's auc: 0.961605\n",
      "[125]\tvalid_0's auc: 0.961605\n",
      "[126]\tvalid_0's auc: 0.96161\n",
      "[127]\tvalid_0's auc: 0.961626\n",
      "[128]\tvalid_0's auc: 0.961626\n",
      "[129]\tvalid_0's auc: 0.96163\n",
      "[130]\tvalid_0's auc: 0.961646\n",
      "[131]\tvalid_0's auc: 0.961678\n",
      "[132]\tvalid_0's auc: 0.961672\n",
      "[133]\tvalid_0's auc: 0.961673\n",
      "[134]\tvalid_0's auc: 0.96171\n",
      "[135]\tvalid_0's auc: 0.96171\n",
      "[136]\tvalid_0's auc: 0.961724\n",
      "[137]\tvalid_0's auc: 0.961723\n",
      "[138]\tvalid_0's auc: 0.961726\n",
      "[139]\tvalid_0's auc: 0.961731\n",
      "[140]\tvalid_0's auc: 0.961736\n",
      "[141]\tvalid_0's auc: 0.961751\n",
      "[142]\tvalid_0's auc: 0.961759\n",
      "[143]\tvalid_0's auc: 0.961777\n",
      "[144]\tvalid_0's auc: 0.961777\n",
      "[145]\tvalid_0's auc: 0.961779\n",
      "[146]\tvalid_0's auc: 0.961782\n",
      "[147]\tvalid_0's auc: 0.961782\n",
      "[148]\tvalid_0's auc: 0.961796\n",
      "[149]\tvalid_0's auc: 0.961799\n",
      "[150]\tvalid_0's auc: 0.961806\n",
      "[151]\tvalid_0's auc: 0.961804\n",
      "[152]\tvalid_0's auc: 0.961805\n",
      "[153]\tvalid_0's auc: 0.961794\n",
      "[154]\tvalid_0's auc: 0.961802\n",
      "[155]\tvalid_0's auc: 0.961805\n",
      "[156]\tvalid_0's auc: 0.961821\n",
      "[157]\tvalid_0's auc: 0.961853\n",
      "[158]\tvalid_0's auc: 0.96187\n",
      "[159]\tvalid_0's auc: 0.961875\n",
      "[160]\tvalid_0's auc: 0.961877\n",
      "[161]\tvalid_0's auc: 0.961889\n",
      "[162]\tvalid_0's auc: 0.961894\n",
      "[163]\tvalid_0's auc: 0.961898\n",
      "[164]\tvalid_0's auc: 0.961901\n",
      "[165]\tvalid_0's auc: 0.961911\n",
      "[166]\tvalid_0's auc: 0.961911\n",
      "[167]\tvalid_0's auc: 0.961915\n",
      "[168]\tvalid_0's auc: 0.961925\n",
      "[169]\tvalid_0's auc: 0.961925\n",
      "[170]\tvalid_0's auc: 0.961929\n",
      "[171]\tvalid_0's auc: 0.961949\n",
      "[172]\tvalid_0's auc: 0.961945\n",
      "[173]\tvalid_0's auc: 0.961945\n",
      "[174]\tvalid_0's auc: 0.961944\n",
      "[175]\tvalid_0's auc: 0.961946\n",
      "[176]\tvalid_0's auc: 0.961952\n",
      "[177]\tvalid_0's auc: 0.961956\n",
      "[178]\tvalid_0's auc: 0.961958\n",
      "[179]\tvalid_0's auc: 0.961971\n",
      "[180]\tvalid_0's auc: 0.961998\n",
      "[181]\tvalid_0's auc: 0.961998\n",
      "[182]\tvalid_0's auc: 0.962014\n",
      "[183]\tvalid_0's auc: 0.962018\n",
      "[184]\tvalid_0's auc: 0.962016\n",
      "[185]\tvalid_0's auc: 0.962022\n",
      "[186]\tvalid_0's auc: 0.962031\n",
      "[187]\tvalid_0's auc: 0.96203\n",
      "[188]\tvalid_0's auc: 0.962021\n",
      "[189]\tvalid_0's auc: 0.962021\n",
      "[190]\tvalid_0's auc: 0.962022\n",
      "[191]\tvalid_0's auc: 0.962026\n",
      "[192]\tvalid_0's auc: 0.962038\n",
      "[193]\tvalid_0's auc: 0.962042\n",
      "[194]\tvalid_0's auc: 0.962041\n",
      "[195]\tvalid_0's auc: 0.962035\n",
      "[196]\tvalid_0's auc: 0.962037\n",
      "[197]\tvalid_0's auc: 0.962048\n",
      "[198]\tvalid_0's auc: 0.962054\n",
      "[199]\tvalid_0's auc: 0.962052\n",
      "[200]\tvalid_0's auc: 0.962054\n",
      "[201]\tvalid_0's auc: 0.962041\n",
      "[202]\tvalid_0's auc: 0.962041\n",
      "[203]\tvalid_0's auc: 0.962052\n",
      "[204]\tvalid_0's auc: 0.962051\n",
      "[205]\tvalid_0's auc: 0.962056\n",
      "[206]\tvalid_0's auc: 0.962056\n",
      "[207]\tvalid_0's auc: 0.962069\n",
      "[208]\tvalid_0's auc: 0.962072\n",
      "[209]\tvalid_0's auc: 0.962072\n",
      "[210]\tvalid_0's auc: 0.962062\n",
      "[211]\tvalid_0's auc: 0.962064\n",
      "[212]\tvalid_0's auc: 0.962066\n",
      "[213]\tvalid_0's auc: 0.962066\n",
      "[214]\tvalid_0's auc: 0.962066\n",
      "[215]\tvalid_0's auc: 0.962064\n",
      "[216]\tvalid_0's auc: 0.96206\n",
      "[217]\tvalid_0's auc: 0.962059\n",
      "[218]\tvalid_0's auc: 0.962059\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's auc: 0.962072\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
    "dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
    "dtest = lgb.Dataset(test[feature_cols], label=test['is_attributed'])\n",
    "\n",
    "param = {'num_leaves':64, 'objective':'binary'}\n",
    "param['metric'] = 'auc'\n",
    "num_round = 1000\n",
    "bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model\n",
    "Finally, with the model trained, I'll evaluate it's performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9726727334566094\n"
     ]
    }
   ],
   "source": [
    "ypred = bst.predict(test[feature_cols])\n",
    "score = metrics.roc_auc_score(test['is_attributed'], ypred)\n",
    "print(f'Test score: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
